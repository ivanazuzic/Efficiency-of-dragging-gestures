{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dragging gestures: Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import sklearn.metrics as metrics\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import os, shutil\n",
    "\n",
    "# for linear regression summary\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.diagnostic import normal_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-445a3973854c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;34m'kappa'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'index_of_difficulty-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'kappa'\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;34m'log(kappa+length)'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'index_of_difficulty-log(kappa+length).json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;34m'log(length:alpha+kappa+1)'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'index_of_difficulty-log(length:alpha+kappa+1).json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;34m'w'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'index_of_difficulty-w.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m }\n",
      "\u001b[0;32m/usr/lib/python3.8/json/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0mkwarg\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0motherwise\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mJSONDecoder\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \"\"\"\n\u001b[0;32m--> 293\u001b[0;31m     return loads(fp.read(),\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mparse_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_int\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_int\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "iodModelName = 'log(length:alpha+kappa+1)'\n",
    "# iodModelName = 'kappa'\n",
    "# iodModelName = 'length'\n",
    "centralTendency = 'mean'\n",
    "# centralTendency = 'median'\n",
    "\n",
    "funcIoDs = {\n",
    "    'kappa*length': json.load(open('index_of_difficulty-kappa*length.json')),\n",
    "    'length': json.load(open('index_of_difficulty-' + 'length' +'.json')),\n",
    "    'kappa': json.load(open('index_of_difficulty-' + 'kappa' +'.json')),\n",
    "    'log(kappa+length)': json.load(open('index_of_difficulty-log(kappa+length).json')),\n",
    "    'log(length:alpha+kappa+1)': json.load(open('index_of_difficulty-log(length:alpha+kappa+1).json')),\n",
    "    'w': json.load(open('index_of_difficulty-w.json')),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare folders and erase all figures\n",
    "# only remove folders which are going to be changed by executing this script\n",
    "\n",
    "figuresFoldername = 'figures'\n",
    "drawingTimeHistogramsFoldername = 'drawing_time_histograms'\n",
    "linearRegressionFoldername = 'linear_regressions'\n",
    "takeScreenshots = False\n",
    "useCroatian = True\n",
    "\n",
    "drawingTimeHistogramsFolderPath = figuresFoldername + \"/\" + drawingTimeHistogramsFoldername + \"/\"\n",
    "linearRegressionsFolderPath = figuresFoldername + \"/\" + linearRegressionFoldername \\\n",
    "    + \"/\" + iodModelName \\\n",
    "    + \"/\" + centralTendency + \"/\"\n",
    "participantDataFolderPath = figuresFoldername + \"/participants/\"\n",
    "\n",
    "def saveFigure(figurename):\n",
    "    figurename = figurename.replace(' ', '_').replace('\\n', '')\n",
    "    if(takeScreenshots is True):\n",
    "        plt.savefig(figurename)\n",
    "\n",
    "def resetFigureFolder(foldername):\n",
    "    if(os.path.exists(foldername)):\n",
    "        shutil.rmtree(foldername)\n",
    "    os.makedirs(foldername)\n",
    "\n",
    "if(takeScreenshots is True):\n",
    "    foldersToBeChanged = [\n",
    "        drawingTimeHistogramsFolderPath,\n",
    "        linearRegressionsFolderPath,\n",
    "        participantDataFolderPath\n",
    "    ]\n",
    "    \n",
    "    for foldername in foldersToBeChanged:\n",
    "        print(foldername)\n",
    "        resetFigureFolder(foldername)    \n",
    "\n",
    "def translateWord(word):\n",
    "    retval = \"\"\n",
    "    if(word == \"Cartesian\"):\n",
    "        retval = \"Kartezijev\"\n",
    "    elif(word == \"Polar\"):\n",
    "        retval = \"Polarni\"\n",
    "    elif word == \"Mouse\":\n",
    "        retval = \"Miš\"\n",
    "    elif word == \"Graphic tablet\":\n",
    "        retval = \"Grafički tablet\"\n",
    "    elif word == \"median\":\n",
    "        retval = \"medijan\"\n",
    "    elif word == \"mean\":\n",
    "        retval = \"Arit.sred.\"\n",
    "    else:\n",
    "        retval = word + \" - neprevedeno\"\n",
    "    return retval\n",
    "        \n",
    "def translate(words):\n",
    "    if(useCroatian is False):\n",
    "        return words\n",
    "    \n",
    "    if(type(words) is not list):\n",
    "        return translateWord(words)\n",
    "    \n",
    "    retval = []\n",
    "    for word in words:\n",
    "            retval.append(translateWord(word))\n",
    "    return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: Index(['Participant name', 'Participant age', 'Participant handedness',\n",
      "       'Device', 'Test mode', 'Logging timestamp', 'Function ID',\n",
      "       'Function difficulty', 'Function projection', 'Drawing time',\n",
      "       'Error approx', 'Expert Mouse User', 'Expert Graphic Tablet User'],\n",
      "      dtype='object')\n",
      "[0.0, 1.4011957616300474, 8.823529009988635, 13.06441965548987, 23.673900713773016, 19.111580586016508, 3.4906585039884606, 3.3171915140029697, 10.012886197954964, 12.026278047055234, 22.63148335179949, 23.18715556459974, 0.8340629434426661, 0.0, 10.256299532925587, 12.004836207680889, 21.86663950671117, 21.282024301039097, 3.2508559319954657, 3.5177499396666767, 10.927318931619745, 13.25749919314703, 21.01396130575237, 23.79668114340944]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'log(length:alpha+kappa+1)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-cdcd0a79a905>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetIodsAsArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPROJECTIONS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTEST_MODES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"kappa\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetIodForFunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Polar\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-cdcd0a79a905>\u001b[0m in \u001b[0;36mgetIodForFunc\u001b[0;34m(projection, experimentMode, funcId, iodName)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# retval = np.log2(2 * float(funcIoDs[iodName][str(test)][str(funcId)]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuncIoDs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miodName\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuncId\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'log(length:alpha+kappa+1)'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('logs.csv')\n",
    "\n",
    "print(\"Columns:\", df.columns)\n",
    "# indices of important columns\n",
    "prAgeInd = 1\n",
    "deviceInd = 2\n",
    "testModeInd = 3\n",
    "funcIdInd = 5\n",
    "funcDiffInd = 6\n",
    "funcProjInd = 7\n",
    "drawTimeInd = 8\n",
    "\n",
    "test0data = df[df['Test mode'] == 0]\n",
    "test1data = df[df['Test mode'] == 1]\n",
    "\n",
    "PROJECTIONS = ['Cartesian', 'Polar']\n",
    "FUNC_IDS = [0, 1, 2, 3, 4, 5]\n",
    "DEVICES = ['Mouse', 'Graphic tablet']\n",
    "TEST_MODES = [0, 1]\n",
    "\n",
    "def getIodForFunc(projection, experimentMode, funcId, iodName=iodModelName):\n",
    "    test = 0\n",
    "    if projection == 'Cartesian' and experimentMode == 1:\n",
    "        test = 1\n",
    "    elif projection == 'Polar' and experimentMode == 0:\n",
    "        test = 2\n",
    "    elif projection == 'Polar' and experimentMode == 1:\n",
    "        test = 3\n",
    "    # retval = np.log2(2 * float(funcIoDs[iodName][str(test)][str(funcId)]))\n",
    "    retval = float(funcIoDs[iodName][str(test)][str(funcId)])\n",
    "    return retval\n",
    "\n",
    "def getIodsAsArray(projections, experimentModes, iodName=iodModelName):\n",
    "    iodsArr = []\n",
    "    for experimentMode in experimentModes:\n",
    "        for projection in projections:            \n",
    "            for funcId in FUNC_IDS:\n",
    "                iodsArr.append(getIodForFunc(projection, experimentMode, funcId, iodName))\n",
    "    return iodsArr\n",
    "\n",
    "def getMaxIodForPlot(iodName=iodModelName):\n",
    "    return round(max(getIodsAsArray(PROJECTIONS, TEST_MODES, iodName))) * 1.2\n",
    "\n",
    "print(getIodsAsArray(PROJECTIONS, TEST_MODES, \"kappa\"))\n",
    "print(getIodForFunc(\"Polar\", 1, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drawing time distribution per function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllDrawingTimesForFunc(projection, funcId, device, experimentMode, data=df):\n",
    "    # filter out by projection, Cartesian or Polar\n",
    "    drawingTimes = data[data['Function projection'] == projection]\n",
    "    # filter out by function ID\n",
    "    drawingTimes = drawingTimes[drawingTimes['Function ID'] == funcId]\n",
    "    # filter out by test (experiment mode)\n",
    "    drawingTimes = drawingTimes[drawingTimes['Test mode'] == experimentMode]\n",
    "    # filter out by device\n",
    "    drawingTimes = drawingTimes[drawingTimes['Device'] == device]\n",
    "    \n",
    "    # for each user, find his/her average for this function\n",
    "    participants = list(set(drawingTimes[\"Participant name\"]))\n",
    "    # find average of each participant for this function\n",
    "    retval = []\n",
    "    for participant in participants:\n",
    "        dataForParticipant = drawingTimes[drawingTimes[\"Participant name\"] == participant]\n",
    "        avg = np.mean(dataForParticipant[\"Drawing time\"].values)\n",
    "        retval.append(avg)\n",
    "    \n",
    "    drawingTimes = drawingTimes['Drawing time'].values\n",
    "    \n",
    "    # return this to return ALL drawing times, without calculating mean for each participant\n",
    "    # return drawingTimes\n",
    "    return retval\n",
    "\n",
    "projection = \"Polar\"\n",
    "funcId = 0\n",
    "device = \"Mouse\"\n",
    "experimentMode = 0\n",
    "\n",
    "for experimentMode in TEST_MODES:\n",
    "    for projection in PROJECTIONS:\n",
    "        for device in DEVICES:\n",
    "            for funcId in FUNC_IDS:\n",
    "                dts = getAllDrawingTimesForFunc(projection, funcId, device, experimentMode)\n",
    "\n",
    "                plt.figure()\n",
    "                plt.hist(dts, color=\"teal\", bins=15)\n",
    "                # limits are hard-coded, if I ever have time, I will make the limits calculation smarter\n",
    "                xlim = [0, 15]\n",
    "                ylim = [0, 75]\n",
    "                plt.ylim(xlim)\n",
    "                plt.xlim(ylim)\n",
    "                \n",
    "                # add text with Median an Mean displayed\n",
    "                text = \"Median: %.3f, Mean: %.3f\" % (np.median(dts), np.mean(dts))\n",
    "                plt.text(ylim[1]-1, xlim[1]-1, text, ha='right', va='top', bbox=dict(facecolor='white', alpha=1))\n",
    "                \n",
    "                plt.title(\n",
    "                    \"Mode: %s, Projection: %s, Device: %s, Function: %s\"\n",
    "                     % (experimentMode, translate(projection), translate(device), funcId)\n",
    "                )\n",
    "                plt.ylabel(\"Count\")\n",
    "                plt.xlabel(\"Drawing time [seconds]\")\n",
    "                saveFigure(\n",
    "                    drawingTimeHistogramsFolderPath \\\n",
    "                    + \"mode-\" + str(experimentMode) \\\n",
    "                    + \"_device-\" + device + \\\n",
    "                    \"_function-\" + str(funcId) +\".png\"\n",
    "                )\n",
    "                plt.show()\n",
    "                print(\"Mean: \", np.mean(dts))\n",
    "                print(\"Median: \", np.median(dts))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average drawing time for each curve on each input device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAvgForFunc(projection, funcId, device, experimentMode = 0, data=df):\n",
    "    drawingTimes = getAllDrawingTimesForFunc(projection, funcId, device, experimentMode, data)\n",
    "    \n",
    "    avg = np.mean(drawingTimes) if centralTendency=='mean' else np.median(drawingTimes)\n",
    "    \n",
    "    return avg\n",
    "\n",
    "def getAvgsByFilter(projections, funcIds, devices, experimentModes, iodName=iodModelName, data=df):\n",
    "    times = []\n",
    "    iods = []\n",
    "    for experimentMode in experimentModes:\n",
    "        for device in devices:\n",
    "            for projection in projections:\n",
    "                for funcId in funcIds:\n",
    "                    avg = getAvgForFunc(projection, funcId, device, experimentMode, data=data)\n",
    "                    times.append(avg)\n",
    "                    iods.append(getIodForFunc(projection, experimentMode, funcId, iodName))\n",
    "                    # use this if you want to get ALL drawing times paired with iods\n",
    "                    # avg = getAllDrawingTimesForFunc(projection, funcId, device, experimentMode, data)\n",
    "                    # times.extend(avg)\n",
    "                    # iods.extend([getIodForFunc(projection, experimentMode, funcId)] * len(avg))\n",
    "                    \n",
    "    return times, iods\n",
    "\n",
    "MAX_AVG_DRAW_TIME = round(max(getAvgsByFilter(PROJECTIONS, FUNC_IDS, DEVICES, TEST_MODES, \"kappa\")[0]))\n",
    "MAX_AVG_DRAW_TIME += 0.2 * MAX_AVG_DRAW_TIME\n",
    "\n",
    "# for mode in TEST_MODES:\n",
    "#    print(\"----------------- MODE:\", mode)\n",
    "#    for device in DEVICES:\n",
    "#        print(\":::\", device, \":::\")\n",
    "#        for funcId in FUNC_IDS:\n",
    "#            print(\"--> Function: \", funcId)\n",
    "#            for projection in PROJECTIONS:\n",
    "#                avg = getAvgForFunc(projection, funcId, device, mode)\n",
    "#                print(\"\\t\", projection, \": \", avg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotForExperiment(experimentModes, projections = PROJECTIONS):\n",
    "    for experimentMode in experimentModes:\n",
    "        for device in DEVICES:\n",
    "            plt.figure()\n",
    "            for projection in projections: \n",
    "                times = []\n",
    "                for funcId in funcIds:\n",
    "                    times.append(getAvgForFunc(projection, funcId, device, experimentMode))\n",
    "\n",
    "                iods = (getIodsAsArray([projection], [experimentMode]))\n",
    "                plt.scatter(iods, times, label=projection)\n",
    "\n",
    "\n",
    "            plt.ylabel(\"Drawing time (s)\")\n",
    "            plt.xlabel(\"Index of difficulty\")\n",
    "            plt.ylim([0, MAX_AVG_DRAW_TIME])\n",
    "            plt.xlim([0, getMaxIodForPlot()])\n",
    "            plt.legend(loc='upper left')\n",
    "            plt.title(\"Experiment %d, %s, %s\" %(experimentMode, device, projections) )\n",
    "            \n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotForExperiment([0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateResiduals(model, x, y):\n",
    "    \"\"\"\n",
    "    Creates predictions on the features with the model and calculates residuals\n",
    "    \"\"\"\n",
    "    predictions = model.predict(x)\n",
    "    residuals = abs(y) - abs(predictions)\n",
    "    return residuals, predictions\n",
    "\n",
    "\n",
    "def checkLinearAssumption(model, x, y, axes):\n",
    "    \"\"\"\n",
    "    Linearity: Assumes that there is a linear relationship between the predictors and\n",
    "               the response variable. If not, either a quadratic term or another\n",
    "               algorithm should be used.\n",
    "    \"\"\"\n",
    "    print('Assumption 1: Linear Relationship between the Target and the Feature', '\\n')\n",
    "        \n",
    "    print('Checking with a scatter plot of actual vs. predicted.',\n",
    "           'Predictions should follow the diagonal line.')\n",
    "    \n",
    "    # Calculating residuals for the plot\n",
    "    residuals, predictions = calculateResiduals(model, x, y)\n",
    "    \n",
    "    # Plotting the actual vs predicted values\n",
    "    axes.scatter(x=y, y=predictions, color=\"coral\", edgecolors=\"grey\")\n",
    "    axes.axis(\"equal\")\n",
    "    axes.set_title(\"Actual vs Predicted\")\n",
    "    axes.set_xlabel(\"Actual\")\n",
    "    axes.set_ylabel(\"Predicted\")\n",
    "    axes.grid(True)\n",
    "        \n",
    "    # Plotting the diagonal line\n",
    "    lineCoords = np.arange(np.min(predictions), np.max(predictions))\n",
    "    axes.plot(lineCoords, lineCoords, color=\"black\")\n",
    "    return axes\n",
    "\n",
    "def normalErrorsAssumption(model, x, y, axes, p_value_thresh=0.05):\n",
    "    \"\"\"\n",
    "    Normality: Assumes that the error terms are normally distributed. If they are not,\n",
    "    nonlinear transformations of variables may solve this.\n",
    "               \n",
    "    This assumption being violated primarily causes issues with the confidence intervals\n",
    "    \"\"\"\n",
    "    print('Assumption 2: The error terms are normally distributed', '\\n')\n",
    "    \n",
    "    # Calculating residuals for the Anderson-Darling test\n",
    "    residuals, predictions = calculateResiduals(model, x, y)\n",
    "    \n",
    "    print('Using the Anderson-Darling test for normal distribution')\n",
    "\n",
    "    # Performing the test on the residuals\n",
    "    p_value = normal_ad(residuals)[1]\n",
    "    print('p-value from the test - below 0.05 generally means non-normal:', p_value)\n",
    "    \n",
    "    # Reporting the normality of the residuals\n",
    "    if p_value < p_value_thresh:\n",
    "        print('Residuals are not normally distributed')\n",
    "    else:\n",
    "        print('Residuals are normally distributed')\n",
    "    \n",
    "    # Plotting the residuals distribution\n",
    "    axes.set_title('Distribution of Residuals')\n",
    "    sns.histplot(residuals, ax=axes)\n",
    "    \n",
    "    print()\n",
    "    if p_value > p_value_thresh:\n",
    "        print('Assumption satisfied')\n",
    "    else:\n",
    "        print('Assumption not satisfied')\n",
    "        print()\n",
    "        print('Confidence intervals will likely be affected')\n",
    "        print('Try performing nonlinear transformations on variables')\n",
    "\n",
    "        \n",
    "def multicollinearityAssumption(model, x, y, axes, feature_names=None):\n",
    "    \"\"\"\n",
    "    Multicollinearity: Assumes that predictors are not correlated with each other. If there is\n",
    "                       correlation among the predictors, then either remove prepdictors with high\n",
    "                       Variance Inflation Factor (VIF) values or perform dimensionality reduction\n",
    "                           \n",
    "                       This assumption being violated causes issues with interpretability of the \n",
    "                       coefficients and the standard errors of the coefficients.\n",
    "    \"\"\"\n",
    "    from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "    print('Assumption 3: Little to no multicollinearity among predictors')\n",
    "        \n",
    "    # Plotting the heatmap\n",
    "    sns.heatmap(pd.DataFrame(x, columns=feature_names).corr(), annot=True, ax=axes)\n",
    "    axes.set_title('Correlation of Variables')\n",
    "        \n",
    "    print('Variance Inflation Factors (VIF)')\n",
    "    print('> 10: An indication that multicollinearity may be present')\n",
    "    print('> 100: Certain multicollinearity among the variables')\n",
    "    print('-------------------------------------')\n",
    "       \n",
    "    # Gathering the VIF for each variable\n",
    "    VIF = [variance_inflation_factor(features, i) for i in range(x.shape[1])]\n",
    "    for idx, vif in enumerate(VIF):\n",
    "        print('{0}: {1}'.format(feature_names[idx], vif))\n",
    "        \n",
    "    # Gathering and printing total cases of possible or definite multicollinearity\n",
    "    possible_multicollinearity = sum([1 for vif in VIF if vif > 10])\n",
    "    definite_multicollinearity = sum([1 for vif in VIF if vif > 100])\n",
    "    print()\n",
    "    print('{0} cases of possible multicollinearity'.format(possible_multicollinearity))\n",
    "    print('{0} cases of definite multicollinearity'.format(definite_multicollinearity))\n",
    "    print()\n",
    "\n",
    "    if definite_multicollinearity == 0:\n",
    "        if possible_multicollinearity == 0:\n",
    "            print('Assumption satisfied')\n",
    "        else:\n",
    "            print('Assumption possibly satisfied')\n",
    "            print()\n",
    "            print('Coefficient interpretability may be problematic')\n",
    "            print('Consider removing variables with a high Variance Inflation Factor (VIF)')\n",
    "\n",
    "    else:\n",
    "        print('Assumption not satisfied')\n",
    "        print()\n",
    "        print('Coefficient interpretability will be problematic')\n",
    "        print('Consider removing variables with a high Variance Inflation Factor (VIF)')\n",
    "\n",
    "        \n",
    "def autocorrelationAssumption(model, x, y):\n",
    "    \"\"\"\n",
    "    Autocorrelation: Assumes that there is no autocorrelation in the residuals. If there is\n",
    "                     autocorrelation, then there is a pattern that is not explained due to\n",
    "                     the current value being dependent on the previous value.\n",
    "                     This may be resolved by adding a lag variable of either the dependent\n",
    "                     variable or some of the predictors.\n",
    "    \"\"\"\n",
    "    from statsmodels.stats.stattools import durbin_watson\n",
    "    print('Assumption 4: No Autocorrelation', '\\n')\n",
    "    \n",
    "    # Calculating residuals for the Durbin Watson-tests\n",
    "    residuals, predictions = calculateResiduals(model, x, y)\n",
    "\n",
    "    print('\\nPerforming Durbin-Watson Test')\n",
    "    print('Values of 1.5 < d < 2.5 generally show that there is no autocorrelation in the data')\n",
    "    print('0 to 2< is positive autocorrelation')\n",
    "    print('>2 to 4 is negative autocorrelation')\n",
    "    print('-------------------------------------')\n",
    "    durbinWatson = durbin_watson(residuals)\n",
    "    print('Durbin-Watson:', durbinWatson)\n",
    "    if durbinWatson < 1.5:\n",
    "        print('Signs of positive autocorrelation', '\\n')\n",
    "        print('Assumption not satisfied')\n",
    "    elif durbinWatson > 2.5:\n",
    "        print('Signs of negative autocorrelation', '\\n')\n",
    "        print('Assumption not satisfied')\n",
    "    else:\n",
    "        print('Little to no autocorrelation', '\\n')\n",
    "        print('Assumption satisfied')\n",
    "\n",
    "def homoscedasticityAssumption(model, x, y, axes):\n",
    "    \"\"\"\n",
    "    Homoscedasticity: Assumes that the errors exhibit constant variance\n",
    "    \"\"\"\n",
    "    print('Assumption 5: Homoscedasticity of Error Terms', '\\n')\n",
    "    \n",
    "    print('Residuals should have relative constant variance')\n",
    "        \n",
    "    # Calculating residuals for the plot\n",
    "    residuals, predictions = calculateResiduals(model, x, y)\n",
    "\n",
    "    # Plotting the residuals\n",
    "    indices = np.arange(0, len(residuals))\n",
    "    axes.scatter(x=indices, y=residuals, alpha=0.5)\n",
    "    axes.plot(np.repeat(0, np.max(indices) + 1), color='darkorange', linestyle='--')\n",
    "    axes.set_title('Residuals')\n",
    "\n",
    "    \n",
    "def testRegressionAssumptions(reg, x, y, title):\n",
    "    figure, axes = plt.subplots(1, 3)\n",
    "    figure.set_size_inches(15, 5)\n",
    "    checkLinearAssumption(reg, x, y, axes[0])\n",
    "    normalErrorsAssumption(reg, x, y, axes[1])\n",
    "    # multicollinearityAssumption(reg, x, y, axes[1, 0])\n",
    "    autocorrelationAssumption(reg, x, y)\n",
    "    homoscedasticityAssumption(reg, x, y, axes[2])\n",
    "    \n",
    "    st = figure.suptitle(title)\n",
    "    figure.tight_layout(pad=2)\n",
    "    # shift subplots down:\n",
    "    st.set_y(1)\n",
    "    figure.subplots_adjust(top=0.85)\n",
    "    \n",
    "    saveFigure(linearRegressionsFolderPath + \"_assumptions_\" + title.replace(' ', '_').replace('\\n', ''))\n",
    "    plt.close(figure)\n",
    "\n",
    "\n",
    "def getBasePlotTitle(projections, device, experimentModes):\n",
    "    return \"Linear regression for %s, %s, mode=%s,\\nCentral Tendency=%s,Index Of Difficulty=%s\" \\\n",
    "                   %(projections, device, experimentModes, centralTendency, iodModelName)\n",
    "\n",
    "def getRegressionCoefficients(reg):\n",
    "    x1 = 0\n",
    "    x2 = 1\n",
    "    y1, y2 = reg.predict(np.array([[x1], [x2]]))\n",
    "    # Coefficients: y = ax + b\n",
    "    b = y1\n",
    "    a = (y2 - y1) / (x2 - x1)\n",
    "    return a, b\n",
    "\n",
    "# get x and y data for linear regression\n",
    "def getDataForRegression(projections, experimentModes, device):\n",
    "    y, iods = np.array(getAvgsByFilter(projections, FUNC_IDS, [device], experimentModes))\n",
    "    x = [[iod] for iod in iods]\n",
    "    return x, y\n",
    "\n",
    "def getFormattedRegressionMetrics(reg, x, y):\n",
    "    a, b = getRegressionCoefficients(reg)\n",
    "    y_predicted = reg.predict(x)\n",
    "    mse = metrics.mean_squared_error(y_predicted, y)\n",
    "    rmspe = (np.sqrt(np.mean(np.square((y_predicted - y) / y_predicted)))) * 100\n",
    "    print(rmspe)\n",
    "    return 'y = %.3fx + %.3f\\nR^2 = %.3f\\nRMSE = %.3f\\nRMSPE = %.3f%%' % (a, b, reg.score(x, y), np.sqrt(mse), rmspe)\n",
    "\n",
    "# model metrics :: for evaulating the regression model\n",
    "def printRegressionModelMetrics(reg, x, y):\n",
    "    print(getFormattedRegressionMetrics(reg, x, y))\n",
    "\n",
    "# training and retrieving the model \n",
    "def getRegressionModel(projections, experimentModes, device, axes):\n",
    "    x, y = getDataForRegression(projections, experimentModes, device)\n",
    "    reg = LinearRegression().fit(x, y)\n",
    "    title = getBasePlotTitle(projections, device, experimentModes)\n",
    "    plotDataAndReg(reg, x, y, title, axes)\n",
    "    printRegressionModelMetrics(reg, x, y)\n",
    "    testRegressionAssumptions(reg, x, y, title)\n",
    "\n",
    "    return reg\n",
    "\n",
    "def plotDataAndReg(reg, x, y, title, axes):\n",
    "    axes.scatter(x, y, label=\"Experiment data\", color=\"lightsteelblue\", edgecolors=\"black\")\n",
    "    MAX_IOD = getMaxIodForPlot()\n",
    "\n",
    "    predictX = np.linspace(1, MAX_IOD, 10)\n",
    "    predictY = reg.predict([[x] for x in predictX])\n",
    "    axes.plot(predictX, predictY, color=\"black\", label=\"Linear regression\")\n",
    "    \n",
    "    axes.set_ylabel(\"Drawing time (seconds)\")\n",
    "    axes.set_xlabel(\"Index of difficulty\")\n",
    "    axes.set_ylim([0, MAX_AVG_DRAW_TIME])\n",
    "    axes.set_xlim([0, MAX_IOD])\n",
    "    axes.grid(True)\n",
    "    axes.legend(loc='upper left')\n",
    "    axes.set_title(title)\n",
    "    # axes.axis('scaled')\n",
    "    \n",
    "    axes.text(0, MAX_AVG_DRAW_TIME - 6,\n",
    "             getFormattedRegressionMetrics(reg, x, y),\n",
    "             ha='left', va='top',\n",
    "             bbox=dict(facecolor='white', alpha=1)\n",
    "    )\n",
    "    \n",
    "\n",
    "def validateRegressionModel(reg, projections, experimentModes, device, axes):  \n",
    "    x, y = getDataForRegression(projections, experimentModes, device)\n",
    "    title = getBasePlotTitle(projections, device, experimentModes) + \" VALIDATED\"\n",
    "    \n",
    "    testRegressionAssumptions(reg, x, y, title)\n",
    "    plotDataAndReg(reg, x, y, title, axes)\n",
    "    printRegressionModelMetrics(reg, x, y)\n",
    "    \n",
    "    \n",
    "def trainRegressionModelThenValidate(projections, device):\n",
    "    print(\"\\n\\nSKLEARN\")\n",
    "    MAX_IOD = getMaxIodForPlot()\n",
    "    dim = max(MAX_IOD / 8, MAX_AVG_DRAW_TIME / 4)\n",
    "    (width, height) = dim, dim\n",
    "    figure, axes = plt.subplots(2)\n",
    "    figure.set_size_inches(width, height)\n",
    "    \n",
    "    reg = getRegressionModel(projections, [0], device, axes[0])\n",
    "    validateRegressionModel(reg, projections, [1], device, axes[1])\n",
    "\n",
    "    figure.tight_layout(pad=3)\n",
    "    title = getBasePlotTitle(projections, device, TEST_MODES) + \" BOTH\"\n",
    "    saveFigure(linearRegressionsFolderPath + title.replace(' ', '_').replace('\\n', ''))\n",
    "    \n",
    "    plt.show(figure)\n",
    "    \n",
    "    # print(\"\\n\\nSTATSMODELS\")\n",
    "    # x, y = getDataForRegression(projections, [0], device)\n",
    "    # constx = sm.add_constant(x)\n",
    "    # reg = sm.OLS(y, constx).fit()\n",
    "    # print(reg.summary())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for projections in [[\"Cartesian\"], [\"Polar\"], PROJECTIONS]:\n",
    "    for device in DEVICES:\n",
    "        trainRegressionModelThenValidate(projections, device)\n",
    "        \n",
    "        \n",
    "        #reg2 = getRegressionModel(projections, [0, 1], device)\n",
    "        # test the residuals as shown here: https://jeffmacaluso.github.io/post/LinearRegressionAssumptions/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Participant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = list(set(test0data['Participant name']))\n",
    "\n",
    "print(\"Number of participants:\", len(participants))\n",
    "\n",
    "ages = []\n",
    "handednessFreq = {\n",
    "    \"Left-handed\": 0,\n",
    "    \"Right-handed\": 0,\n",
    "    \"Ambidextrous\": 0\n",
    "}\n",
    "hasExpWTablet = 0\n",
    "hasExpWMouse = 0\n",
    "for participant in participants:\n",
    "    row = df[df['Participant name'] == participant]\n",
    "    age = row['Participant age'].values[0]\n",
    "    handednessFreq[row['Participant handedness'].values[0]] += 1\n",
    "    hasExpWTablet += row['Expert Graphic Tablet User'].values[0]\n",
    "    hasExpWMouse += row['Expert Mouse User'].values[0]\n",
    "    # print(participant, age)\n",
    "    ages.append(age)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(ages, color=\"lightcoral\", bins=15, edgecolor=\"grey\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"Age\")\n",
    "plt.title(\"Participants' age\")\n",
    "if useCroatian is True:    \n",
    "    plt.ylabel(\"Broj\")\n",
    "    plt.xlabel(\"Godine\")\n",
    "    plt.title(\"Starosna distribucija ispitanika\")\n",
    "saveFigure(participantDataFolderPath + \"participant_age\")\n",
    "plt.plot\n",
    "print(\"Average participant age:\", round(np.mean(ages), 3))\n",
    "print(\"Standard deviation:\", round(np.std(ages), 3))\n",
    "\n",
    "print(\"\\n ::::\")\n",
    "\n",
    "for handedness in handednessFreq:\n",
    "    freq = handednessFreq[handedness]\n",
    "    print(\"Number of \" + handedness + \" participants:\", freq)\n",
    "    print(\"Percentage of \" + handedness + \" participants\", round(freq * 1.0 / len(participants), 3)*100, '%')\n",
    "\n",
    "print(\"\\n ::::\")\n",
    "print(\"Number of expert graphic tablet participants:\", hasExpWTablet)\n",
    "print(\"Percentage of expert graphic tablet participants\",\n",
    "      round(hasExpWTablet * 1.0 / len(participants), 3)*100, '%'\n",
    ")\n",
    "\n",
    "print(\"Number of expert mouse participants:\", hasExpWMouse)\n",
    "print(\"Percentage of expert graphic tablet participants\",\n",
    "      round(hasExpWMouse * 1.0 / len(participants), 3)*100, '%'\n",
    ")\n",
    "\n",
    "print(\"\\n ::::\")\n",
    "print(\"Average drawing times\")\n",
    "\n",
    "# Anderson-Darling test for normal distribution unknown mean and variance.\n",
    "def isDataNormallyDistributed(data, p_value_thresh=0.05):\n",
    "    p_value = normal_ad(data)[1]\n",
    "    print('p-value from the test - below 0.05 generally means non-normal:', p_value)\n",
    "    \n",
    "    # Reporting the normality of the residuals\n",
    "    if p_value < p_value_thresh:\n",
    "        print('Data is not normally distributed')\n",
    "    else:\n",
    "        print('Data is normally distributed')\n",
    "    return p_value\n",
    "\n",
    "\n",
    "# separator is semicolon because the 'projections' column has commas in it\n",
    "separator = ';'\n",
    "\n",
    "# Average drawing time per user\n",
    "sortedParticipants = sorted(participants)\n",
    "figure, axes = plt.subplots(len(DEVICES), len([[\"Cartesian\"], [\"Polar\"], PROJECTIONS]))\n",
    "figure.set_size_inches(15, 7)\n",
    "\n",
    "for k, device in enumerate(DEVICES):\n",
    "    for j, projections in enumerate([[\"Cartesian\"], [\"Polar\"], PROJECTIONS]):\n",
    "        pltData = []\n",
    "        print(\"Participant\",\"Device\", \"Projections\",\"Drawing Time Mean\", \"Drawing time stdev\", sep=separator)\n",
    "        for i in range(len(sortedParticipants)):\n",
    "            participant = sortedParticipants[i]\n",
    "            dts = []\n",
    "            for funcId in FUNC_IDS:\n",
    "                for experimentMode in TEST_MODES:\n",
    "                    drawingTimes = df[df['Participant name'] == participant]\n",
    "                    drawingTimes, _ = getAvgsByFilter(projections, [funcId], [device], [experimentMode], data=drawingTimes)\n",
    "                    dts.append(drawingTimes)\n",
    "            # print(participant, device, projections, round(np.mean(dts), 4), round(np.std(dts), 4), sep=separator)\n",
    "            pltData.append(np.mean(dts))\n",
    "        # print()\n",
    "        ax = axes[k][j]\n",
    "        ax.hist(pltData, color='mediumseagreen', bins=15, edgecolor=\"black\")\n",
    "\n",
    "        pValueNormDist = isDataNormallyDistributed(np.array(pltData))\n",
    "        \n",
    "        title = \"Average drawing time for \\n Device %s, Projection(s) %s\" %(device, projections)\n",
    "        ax.set_ylabel(\"Count\")\n",
    "        ax.set_xlabel(\"Average drawing time [seconds]\\nNorm dist p_value=%.5f\" % (pValueNormDist))\n",
    "        \n",
    "        if useCroatian is True:\n",
    "            title = \"Prosječno vrijeme crtanja za: \\n Uređaj: %s, Projekcija(e): %s\" %(translate(device), \n",
    "                                                                                   translate(projections))\n",
    "            ax.set_ylabel(\"Broj\")\n",
    "            ax.set_xlabel(\"Vrijeme [s]\") #\"\\nNorm dist p_value=%.5f\" % (pValueNormDist))\n",
    "        ax.set_title(title)\n",
    "        \n",
    "        # this lim is hard-coded. if I ever have time, I should make this soft-coded :)\n",
    "        ax.set_ylim([0, 7])\n",
    "        ax.set_xlim([0, MAX_AVG_DRAW_TIME])\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "figure.tight_layout(pad=2)\n",
    "saveFigure(participantDataFolderPath + \"Average_drawing_times\")\n",
    "plt.show()\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortedParticipants = sorted(participants)\n",
    "\n",
    "print(\"Participant index\", \"Mouse error mean\", \"Mouse error stdev\", \"Graphic tablet error mean\", \"Graphic tablet error stdev\", sep=separator)\n",
    "avgs = { \"Mouse\":[], \"Graphic tablet\":[]}\n",
    "for i in range(len(sortedParticipants)):\n",
    "    participant = sortedParticipants[i]\n",
    "    print(participant, end='')\n",
    "    for device in DEVICES:\n",
    "        # epm = error per move\n",
    "        epms = []\n",
    "        for experimentMode in TEST_MODES:\n",
    "            filename = \"../Results_backup%s/%s/%s\" %(experimentMode, participant, device)\n",
    "            files = os.listdir(filename)\n",
    "            for file in files:\n",
    "                funcId = int(file[3])\n",
    "                projtmp = file[10]\n",
    "                projection = \"Cartesian\"\n",
    "                if(projtmp in [\"2\", \"3\"]):\n",
    "                    projection = \"Polar\"\n",
    "                # filter out by projection, Cartesian or Polar\n",
    "                errors = df[df['Function projection'] == projection]\n",
    "                # filter out by function ID\n",
    "                errors = errors[errors['Function ID'] == funcId]\n",
    "                # filter out by test (experiment mode)\n",
    "                errors = errors[errors['Test mode'] == experimentMode]\n",
    "                errors = errors[errors['Participant name'] == participant]\n",
    "                # filter out by device\n",
    "                errors = errors[errors['Device'] == device]\n",
    "                f = open(filename + \"/\" + file)\n",
    "                \n",
    "                # find the stdev of the error by dividing the sum of errors with the square root of\n",
    "                # the number of points (this is the stdev formula)\n",
    "                \n",
    "                errorVal = np.mean(errors[\"Error approx\"].values) * 1.0 / len(f.readlines())\n",
    "                epms.append(errorVal)\n",
    "                f.close()\n",
    "                # print(participant, projection, \"(%s)\" %projtmp, experimentMode, funcId, device, errorVal)\n",
    "        print('', round(np.mean(epms), 6), round(np.std(epms), 6), sep=separator, end='')\n",
    "        avgs[device].append(np.mean(epms))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_riemann_integral(f, x0, x1, numpoints):\n",
    "    integral_approx = 0\n",
    "    # distance between two points (will be very small)\n",
    "    delta = (x1 - x0) / numpoints\n",
    "    i = 0\n",
    "    for i in range(numpoints):\n",
    "        # put integral_approx calculation inside try-except\n",
    "        # in case we get \"division by zero\" exception.\n",
    "        if(i % (numpoints / 10) == 0):\n",
    "            # this condition is meant to represent a \"loading bar\"\n",
    "            # it will print the current percentage of points processed\n",
    "            # print(round(x0 / x1, 3) * 100, \"%  done\")\n",
    "            pass\n",
    "        try:\n",
    "            # Riemann sum\n",
    "            integral_approx += abs(f(x0) * delta)\n",
    "        except Exception as e:\n",
    "            # this might, on very rare occassions, be\n",
    "            # \"division by zero\"\n",
    "            print(e)\n",
    "        finally:\n",
    "            x0 += delta\n",
    "    return integral_approx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxAvg = np.max([np.max(avgs[\"Mouse\"]), np.max(avgs[\"Graphic tablet\"])])\n",
    "minAvg = np.min([np.min(avgs[\"Mouse\"]), np.min(avgs[\"Graphic tablet\"])])\n",
    "xlim = [minAvg - 0.005, maxAvg + 0.005]\n",
    "    \n",
    "figure, (ax1, ax2) = plt.subplots(2)\n",
    "figure.set_size_inches(5, 8)\n",
    "ax1.hist(avgs[\"Mouse\"], color=\"lightcoral\", bins=15, edgecolor=\"black\")\n",
    "\n",
    "pValueNormDist = isDataNormallyDistributed(np.array(avgs[\"Mouse\"]))\n",
    "\n",
    "title = \"Average error rate distribution, Mouse\"\n",
    "ax1.set_xlabel(\"Average error, Polar and Cartesian combined\\nNorm dist p_value=%.5f\" % (pValueNormDist))\n",
    "ax1.set_ylabel(\"Participant count\")\n",
    "\n",
    "if useCroatian is True:\n",
    "    title = \"Distrubucija prosječne pogreške, Miš\"\n",
    "    ax1.set_xlabel(\"Iznos pogreške\")\n",
    "    ax1.set_ylabel(\"Broj ispitanika\")\n",
    "    \n",
    "\n",
    "ax1.set_title(title)\n",
    "ax1.set_ylim([0, 6])\n",
    "ax1.set_xlim(xlim)\n",
    "\n",
    "ax2.hist(avgs[\"Graphic tablet\"], color=\"lightcoral\", bins=15, edgecolor=\"black\")\n",
    "\n",
    "pValueNormDist = isDataNormallyDistributed(np.array(avgs[\"Graphic tablet\"]))\n",
    "\n",
    "title = \"Average error rate distribution, Graphic tablet\"\n",
    "\n",
    "ax2.set_xlabel(\"Average error, Polar and Cartesian combined\\nNorm dist p_value=%.5f\" % (pValueNormDist))\n",
    "ax2.set_ylabel(\"Participant count\")\n",
    "if useCroatian is True:\n",
    "    title = \"Distribucija prosječne pogreške, Grafički tablet\"\n",
    "    ax2.set_xlabel(\"Iznos pogreške\")\n",
    "    ax2.set_ylabel(\"Broj ispitanika\")\n",
    "\n",
    "ax2.set_title(title)\n",
    "ax2.set_ylim([0, 6])\n",
    "ax2.set_xlim(xlim)\n",
    "\n",
    "figure.tight_layout(pad=2)\n",
    "saveFigure(participantDataFolderPath + \"Error_rates_dist\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "## Throughput calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortedParticipants = sorted(participants)\n",
    "\n",
    "avgs = { \"Mouse\":[], \"Graphic tablet\":[]}\n",
    "for i in range(len(sortedParticipants)):\n",
    "    participant = sortedParticipants[i]\n",
    "    # print(participant, end='')\n",
    "    for device in DEVICES:\n",
    "        for experimentMode in TEST_MODES:\n",
    "            filename = \"../Results_backup%s/%s/%s\" %(experimentMode, participant, device)\n",
    "            files = os.listdir(filename)\n",
    "            for file in files:\n",
    "                funcId = int(file[3])\n",
    "                projtmp = file[10]\n",
    "                projection = \"Cartesian\"\n",
    "                if(projtmp in [\"2\", \"3\"]):\n",
    "                    projection = \"Polar\"\n",
    "                # we are searching for an entry in the logs which can tell us\n",
    "                # the average MT for user\n",
    "                # and the st dev of error rate for user.\n",
    "                # from the stdev of error rate, we will caluclate effective width of target (W_e)\n",
    "                # and from that we'll get effective index of difficulty - ID_e\n",
    "                # when we divide ID_e by the MT of the user, we get the user's throughput for a single curve\n",
    "                # and then we find the mean of all throughputs for this user, which we\n",
    "                # then use for t-test to compare the two pointing devices\n",
    "                    \n",
    "                # filter out by projection, Cartesian or Polar\n",
    "                participantMovement = df[df['Function projection'] == projection]\n",
    "                # filter out by function ID\n",
    "                participantMovement = participantMovement[participantMovement['Function ID'] == funcId]\n",
    "                # filter out by test (experiment mode)\n",
    "                participantMovement = participantMovement[participantMovement['Test mode'] == experimentMode]\n",
    "                participantMovement = participantMovement[participantMovement['Participant name'] == participant]\n",
    "                # filter out by device\n",
    "                participantMovement = participantMovement[participantMovement['Device'] == device]\n",
    "                f = open(filename + \"/\" + file)\n",
    "                \n",
    "                # find the stdev of the error by dividing the sum of errors with the square root of\n",
    "                # the number of points (this is the stdev formula)\n",
    "                numOfPointsDrawn = len(f.readlines())\n",
    "                f.close()\n",
    "                \n",
    "                # this is the average error which the user made on this specific curve\n",
    "                errorVal = np.mean(participantMovement[\"Error approx\"].values) * 1.0 / np.sqrt(numOfPointsDrawn)\n",
    "                \n",
    "                # this is from the effective target width (Fitts law), a true-tried-tested formula\n",
    "                W_e = 4.133 * errorVal\n",
    "                \n",
    "                # calculate effective ID_e for this W_e\n",
    "                kappa = getIodForFunc(projection, experimentMode, funcId, 'kappa')\n",
    "                print(kappa)\n",
    "                \n",
    "                length = getIodForFunc(projection, experimentMode, funcId, 'length')\n",
    "                \n",
    "                Id_e = \n",
    "                \n",
    "                # print(participant, projection, \"(%s)\" %projtmp, experimentMode, funcId, device, errorVal)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
